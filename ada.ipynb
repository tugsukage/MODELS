{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-5ym5pX1um9"
      },
      "outputs": [],
      "source": [
        "# Download the aclImdb dataset\n",
        "!wget -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim sentence_transformers"
      ],
      "metadata": {
        "id": "TKa8uM_s1yay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, string, time, logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "gm7MZUSk10NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/aclImdb\"  # change path if needed\n",
        "\n",
        "def read_reviews(base_dir):\n",
        "    def read_folder(path, label):\n",
        "        texts, labels = [], []\n",
        "        for fname in os.listdir(path):\n",
        "            fpath = os.path.join(path, fname)\n",
        "            if os.path.isfile(fpath):\n",
        "                with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                    texts.append(f.read())\n",
        "                    labels.append(label)\n",
        "        return texts, labels\n",
        "\n",
        "    train_pos, y_train_pos = read_folder(os.path.join(base_dir, \"train\", \"pos\"), 1)\n",
        "    train_neg, y_train_neg = read_folder(os.path.join(base_dir, \"train\", \"neg\"), 0)\n",
        "    test_pos, y_test_pos = read_folder(os.path.join(base_dir, \"test\", \"pos\"), 1)\n",
        "    test_neg, y_test_neg = read_folder(os.path.join(base_dir, \"test\", \"neg\"), 0)\n",
        "\n",
        "    return train_pos+train_neg, y_train_pos+y_train_neg, test_pos+test_neg, y_test_pos+y_test_neg\n",
        "\n",
        "X_train_raw, y_train, X_test_raw, y_test = read_reviews(DATA_DIR)\n",
        "print(f\"Loaded train={len(X_train_raw)}, test={len(X_test_raw)}\")\n"
      ],
      "metadata": {
        "id": "OrXOR5Po13FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML_RE = re.compile(r\"<.*?>\")\n",
        "PUNCT_TABLE = str.maketrans(\"\", \"\", string.punctuation)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = HTML_RE.sub(\" \", text)\n",
        "    text = text.lower()\n",
        "    text = text.translate(PUNCT_TABLE)\n",
        "    return text\n",
        "\n",
        "X_train = [clean_text(t) for t in X_train_raw]\n",
        "X_test = [clean_text(t) for t in X_test_raw]\n"
      ],
      "metadata": {
        "id": "0ItsTNCu15ee"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_log(name, y_true, y_pred, results):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"\\n[{name}]\")\n",
        "    print(f\"Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "    results.append({\"Embedding\":name,\"Accuracy\":acc,\"Precision\":prec,\"Recall\":rec,\"F1\":f1})\n",
        "\n",
        "def tune_adaboost(X_train_emb, y_train, name):\n",
        "    base_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    ada = AdaBoostClassifier(\n",
        "        estimator=base_tree,   # ← ЭНЭ ХАМГИЙН ЧУХАЛ\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        \"n_estimators\": [50],          # хурдны үүднээс багасгав\n",
        "        \"learning_rate\": [0.5],\n",
        "        \"estimator__max_depth\": [1]\n",
        "    }\n",
        "\n",
        "    print(f\"\\n[{name}] Starting GridSearchCV...\")\n",
        "    grid = GridSearchCV(\n",
        "        ada,\n",
        "        param_grid,\n",
        "        scoring=\"f1\",\n",
        "        cv=3,\n",
        "        n_jobs=1,        # Colab-д тогтвортой\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train_emb, y_train)\n",
        "\n",
        "    print(f\"[{name}] Best params: {grid.best_params_}, Best CV F1={grid.best_score_:.4f}\")\n",
        "    return grid.best_estimator_, grid.best_params_\n"
      ],
      "metadata": {
        "id": "Mt9EcTNI164Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "count_vec = CountVectorizer()\n",
        "X_train_counts = count_vec.fit_transform(X_train)\n",
        "X_test_counts = count_vec.transform(X_test)\n",
        "X_train_tf = normalize(X_train_counts, norm=\"l1\")\n",
        "X_test_tf = normalize(X_test_counts, norm=\"l1\")\n",
        "\n",
        "ada_tf, params_tf = tune_adaboost(X_train_tf, y_train, \"TF\")\n",
        "evaluate_and_log(\"TF\", y_test, ada_tf.predict(X_test_tf), results)\n"
      ],
      "metadata": {
        "id": "zeVLhmjp18cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec_bin = CountVectorizer(binary=True, max_features=10000)\n",
        "X_train_bin = count_vec_bin.fit_transform(X_train)\n",
        "X_test_bin = count_vec_bin.transform(X_test)\n",
        "idf = TfidfTransformer(use_idf=True, norm=None)\n",
        "X_train_idf = idf.fit_transform(X_train_bin)\n",
        "X_test_idf = idf.transform(X_test_bin)\n",
        "\n",
        "ada_idf, params_idf = tune_adaboost(X_train_idf, y_train, \"IDF-only\")\n",
        "evaluate_and_log(\"IDF-only\", y_test, ada_idf.predict(X_test_idf), results)\n"
      ],
      "metadata": {
        "id": "xwRVTv3U199C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_uni = TfidfVectorizer(ngram_range=(1,1))\n",
        "X_train_uni = tfidf_uni.fit_transform(X_train)\n",
        "X_test_uni = tfidf_uni.transform(X_test)\n",
        "\n",
        "ada_uni, params_uni = tune_adaboost(X_train_uni, y_train, \"TF-IDF unigram\")\n",
        "evaluate_and_log(\"TF-IDF unigram\", y_test, ada_uni.predict(X_test_uni), results)\n"
      ],
      "metadata": {
        "id": "f6e2jHJc1_Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens = [t.split() for t in X_train]\n",
        "test_tokens = [t.split() for t in X_test]\n",
        "\n",
        "w2v = Word2Vec(sentences=train_tokens, vector_size=100, window=5, min_count=2, sg=0, epochs=5)\n",
        "def avg_vec(tokens, model):\n",
        "    vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
        "    return np.mean(vecs, axis=0) if vecs else np.zeros(model.wv.vector_size)\n",
        "\n",
        "X_train_w2v = np.vstack([avg_vec(t, w2v) for t in train_tokens])\n",
        "X_test_w2v = np.vstack([avg_vec(t, w2v) for t in test_tokens])\n",
        "\n",
        "ada_w2v, params_w2v = tune_adaboost(X_train_w2v, y_train, \"Word2Vec CBOW\")\n",
        "evaluate_and_log(\"Word2Vec CBOW\", y_test, ada_w2v.predict(X_test_w2v), results)\n"
      ],
      "metadata": {
        "id": "4ijHUks32BAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_train_st = st_model.encode(X_train, batch_size=32, convert_to_numpy=True)\n",
        "X_test_st = st_model.encode(X_test, batch_size=32, convert_to_numpy=True)\n",
        "\n",
        "ada_st, params_st = tune_adaboost(X_train_st, y_train, \"BERT embeddings\")\n",
        "evaluate_and_log(\"BERT embeddings\", y_test, ada_st.predict(X_test_st), results)\n"
      ],
      "metadata": {
        "id": "qvi0UlUL2CYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results).sort_values(by=\"F1\", ascending=False)\n",
        "print(\"\\n=== Final Comparison ===\")\n",
        "print(df[[\"Embedding\",\"Accuracy\",\"F1\"]].to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyRhm_m82GVE",
        "outputId": "9fe098e4-a099-4d44-a2ea-eeb86d951934"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Final Comparison ===\n",
            "      Embedding  Accuracy       F1\n",
            "BERT embeddings   0.75688 0.754801\n",
            "             TF   0.71440 0.749086\n",
            " TF-IDF unigram   0.70456 0.748827\n",
            "       IDF-only   0.71124 0.734781\n",
            "  Word2Vec CBOW   0.73676 0.726419\n"
          ]
        }
      ]
    }
  ]
}